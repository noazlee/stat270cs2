---
title: "Workingdoccasetsuyd2"
format: html
editor: visual
---

```{r setup}
#| include: false
# Load necessary packages
library(tidyverse)
library(tidymodels)
library(dplyr)
library(ggformula)
library(ggplot2) 
library(GGally)
##install.packages("vip")
library(mosaic)
library(ranger)
library(vip)
library(caret)
tidymodels_prefer(quiet = TRUE) 
```

```{r}
mnist100_tbl <- read_csv("https://aloy.github.io/stat270/data/digits26.csv", show_col_types = FALSE) |>
  mutate(digit=as.factor(digit)) |>
  slice_head(n=100)
dim(mnist100_tbl)

mnist_tbl <- read_csv("https://aloy.github.io/stat270/data/digits26.csv", 
                      show_col_types = FALSE) |> 
  mutate(digit=as.factor(digit)) |>
  filter(digit == c(2,6))

dim(mnist_tbl)
```

```{r}
plot_digit <- function(row) {
  digit_mat <- row |>
    select(-digit)|>
    as.numeric() |>
    matrix(nrow = 28)
  
  image(digit_mat[,28:1])
}
```

```{r}
pull(mnist_tbl[1,], digit)
pull(mnist_tbl[2,], digit)
```

```{r}
plot_digit(mnist_tbl[8,])

plot_digit(mnist_tbl[81,])
```

```{r}
calc_prop <- function (region, row) {
  # Take row from mnist and transform into a "digit" matrix
  digit_mat <-  row |>
    as.numeric() |>
    matrix(nrow = 28) |>
    t()
  
  # Find positions of pixels from "region"
  pos <- (region==1)
  
  # Subset "digit" to the positions and count dark pixels (grey>20)
  dark <- digit_mat[pos] > 20 
  
  # Return proportion of dark pixels of "image" in "region"
  return(sum(dark) / sum(pos))
}
```

```{r}
calc_prop <- function(region, row) {
  digit_mat <- matrix(as.numeric(row), nrow = 28, byrow = TRUE)
  pos <- (region == 1)
  dark_pixels <- digit_mat[pos] > 20  # Threshold for darkness
  prop_dark <- sum(dark_pixels) / sum(pos)
  return(prop_dark)
}

```

```{r}
##what is the threshold for a dark pixel? 

threshold <- 50 #assigned 50 for now

pixel_matrix <- as.matrix(select(mnist_tbl, -digit))

dark_pixels <- pixel_matrix > threshold

num_dark_pixels_total <- rowSums(dark_pixels)

num_dark_pixels_total

#prop of dark pixels
total_pixels <- ncol(pixel_matrix)

prop_dark_pixels_total <- num_dark_pixels_total / total_pixels 

prop_dark_pixels_total


mnist_counts <- mnist_tbl |>
  mutate(num_dark_pixels_total = num_dark_pixels_total)

head(mnist_counts, 10)

##summary(mnist_counts) ## hard to read, i.e don't know how to read 

ggplot(mnist_counts, aes(x = digit, y = num_dark_pixels_total)) +
  geom_boxplot() +
  labs(
    title = "Total Number of Dark Pixels by Digit",
    x = "Digit",
    y = "Number of Dark Pixels"
  )

ggplot(mnist_counts, aes(x = digit, y = prop_dark_pixels_total)) +
  geom_boxplot() +
  labs(
    title = "Total Prop of Dark Pixels by Digit",
    x = "Digit",
    y = "Prop of Dark Pixels"
  )

anovaTest <- aov(prop_dark_pixels_total ~ digit, data = mnist_counts)

summary(anovaTest)

```

```{r}
mnist_counts['num_dark_pixels_total']
```

The p value of digits is 0.00303, which is pretty significant. We decided to include this into our model as a feature.

```{r}
## The only region feature we are adding into our model
special_section <- matrix(0, nrow = 28, ncol = 28)
special_section[9:16, 6:13] <- 1
special_section_tbl <- as_tibble(special_section)

plot_region(special_section)
```

```{r}

conflicted::conflicts_prefer(base::sum)

mnist_featureFINAL <- mnist_tbl |>
  mutate(
    prop_special = apply(select(cur_data(), V1:V784), 1, function(row) calc_prop(special_section, row)) 
  )

mnist_featureFINAL['prop_special']
```

```{r}
mnist_tbl['countBlack'] <- mnist_counts['num_dark_pixels_total']

mnist_tbl['propArea'] <- mnist_featureFINAL['prop_special']

mnist_tbl <- mnist_tbl |>
  mutate(
    prop_special = apply(select(cur_data(), V1:V784), 1, function(row) calc_prop(special_section, row))
  )


mnist_tbl['propArea']
mnist_tbl['countBlack']

```

```{r}
mnist_tbl
```

```{r}
##split data into training and validation and testing set 
set.seed(11012024)
mnist_split <- initial_split(mnist_tbl, prop = 0.7, strata = digit)
mnist_train <- training(mnist_split)
mnist_tests<- testing(mnist_split)

mnist_test_val_split <- initial_split(mnist_tests, prop = 0.5, strata = digit)
mnist_validation <- training(mnist_test_val_split)
mnist_testing <- testing(mnist_test_val_split)

```

Random Forest Model:

```{r}
rf_spec <- 
  rand_forest(trees = 200, mtry = 4) |>
  set_mode("classification") |>
  set_engine("ranger", importance = "impurity")

ranger_recipe <- 
  recipe(formula = digit ~ ., data = mnist_train)

ranger_workflow <- workflow() |>
  add_recipe(ranger_recipe) |>
  add_model(rf_spec) 


(rf_fit <- fit(ranger_workflow, data = mnist_train))
```

```{r}
rf_pred <- augment(rf_fit, new_data=mnist_validation)
```

```{r}
rf_pred
```

```{r}
confusion_matrix <- table(Predicted = rf_pred$.pred_class, True = rf_pred$digit)
confusion_matrix
```

```{r}
yardstick::roc_auc(
  data = rf_pred,
  digit,
  .pred_2,
  event_level = "first"
)
```

1 - 0.000467 = 0.9995

```{r}
vip::vip(rf_fit)
```

Most important variables: V243, propArea, V320, V299, V271, V376, V374, V346, V319, V348

```{r}
plot_digit2 <- function(row,  highlight_pixels = c(243, 320, 299, 271, 376, 374, 346, 319, 348)) {
  digit_mat <- matrix(0, nrow = 28, ncol = 28)
  
  digit_mat[highlight_pixels] <- 1
  
  image(digit_mat[,28:1])
}
```

```{r}
plot_digit2(mnist_tbl[8,])
```

```{r}
plot_digit(mnist_tbl[8,])

plot_digit(mnist_tbl[81,])
```

Investigating wrong predictions in our model:

```{r}
misclassified_records <- rf_pred |>
  filter(.pred_class != digit)

misclassified_records
```

```{r}
plot_digit(misclassified_records[1,])
```

```{r}
plot_digit(misclassified_records[,])
```

The model was wrong when: - The digit was rotated - The digit had unusual thickness - The digit was badly drawn and hard to recognise as a human

Tuning the Random Forest to get the right amount of trees: 

```{r}

ranger_recipe <- 
  recipe(formula = digit ~ ., data = mnist_train)

ranger_folds <- vfold_cv(mnist_train, v = 10, strata = digit)

rf_spec_tune <- 
rand_forest(trees = tune(), mtry = tune()) |>
set_mode("classification") |>
set_engine("ranger", importance = "impurity")

ranger_workflow_tune <- 
  workflow() |>
  add_recipe(ranger_recipe) |>
  add_model(rf_spec_tune) 

ranger_grid <- grid_regular(
  trees(range = c(50, 150)),   
  mtry(range = c(21, 30)), # How do you chose these values
  levels = 5
)

ranger_tune <- tune_grid(
  ranger_workflow_tune, 
  resamples = ranger_folds, 
  grid = ranger_grid
)

best_cc <- select_by_one_std_err(
  ranger_tune, 
  metric = "roc_auc", 
  trees, 
  mtry
)

best_cc
```
best mtry = 23
best trees = 75

updated tuned best random forest model
```{r}
rf_spec_best <- 
  rand_forest(trees = 75, mtry = 23) |>
  set_mode("classification") |>
  set_engine("ranger", importance = "impurity")

ranger_recipe <- 
  recipe(formula = digit ~ ., data = mnist_train) |>
  step_rm(prop_special)

ranger_workflow <- workflow() |>
  add_recipe(ranger_recipe) |>
  add_model(rf_spec_best) 


(rf_fit_best <- fit(ranger_workflow, data = mnist_train))
```

```{r}
rf_pred_best <- augment(rf_fit_best, new_data = mnist_validation)
```

```{r}
rf_pred_best
```

```{r}
confusion_matrix_best <- table(Predicted = rf_pred_best$.pred_class, True = rf_pred_best$digit)
confusion_matrix_best
```

```{r}
yardstick::roc_auc(
  data = rf_pred_best,
  digit,
  .pred_2,
  event_level = "first"
)
```
roc_auc = 0.9996967 (A little bit worse but it is whatever)

```{r}
vip::vip(rf_fit_best)
```
Most important variables: V348, propArea, V375, V347, V374, V270, V321, V373, V320, V625

Trying a diff model (KNN): 

```{r}
knn_model <- nearest_neighbor(neighbors = tune()) |> 
    set_engine("kknn") |>
    set_mode("classification")

knn_rec <- recipe(formula = digit ~ ., data = mnist_train) |> 
  step_zv(all_predictors()) |>
  step_normalize(all_predictors())

knn_wf <- workflow() |> 
    add_recipe(knn_rec) |>
    add_model(knn_model) 

set.seed(11012024)

my_folds <- vfold_cv(mnist_train, v = 5) 

k_grid <- grid_regular(neighbors(range = c(3, 19)), levels = 17) 

cv_results <- tune_grid(object = knn_wf, resamples = my_folds, grid = k_grid) 
```

```{r}
autoplot(cv_results,  metric = "accuracy") 
show_best(cv_results, metric = "accuracy")
```

```{r}
knn_model_final <- nearest_neighbor(neighbors = 7) |> 
    set_engine("kknn") |>
    set_mode("classification")

knn_rec <- recipe(formula = digit ~ ., data = mnist_train) |> 
  step_zv(all_predictors()) |>
  step_normalize(all_predictors())

knn_wf <- workflow() |> 
    add_recipe(knn_rec) |>
    add_model(knn_model_final) 

knn_fit <- knn_wf |> fit(data=mnist_train)
```

```{r}
knn_predictions <- augment(knn_fit, new_data=mnist_validation)
```

```{r}
confusion_matrix <- table(Predicted = knn_predictions$.pred_class, True = knn_predictions$digit)
confusion_matrix
```

```{r}
yardstick::roc_auc(
  data = knn_predictions,
  digit,
  .pred_2,
  event_level = "first"
)
```

KNN performs well but we aren't able to get the most important variables like with random forest.

```{r}
misclassified_records_knn <- knn_predictions |>
  filter(.pred_class != digit)

misclassified_records_knn
```

```{r}
plot_digit(misclassified_records_knn[7,])
```

KNN seemed to misclassify 2 as 6 more oftern while random forest misclassified 6 as 2 more often.

Testing RF model on the test set:

```{r}
rf_pred_test <- augment(rf_fit, new_data=mnist_testing)
```

```{r}
rf_pred_test
```

```{r}
confusion_matrix <- table(Predicted = rf_pred_test$.pred_class, True = rf_pred_test$digit)
confusion_matrix
```

```{r}
yardstick::roc_auc(
  data = rf_pred_test,
  digit,
  .pred_2,
  event_level = "first"
)
```

1-0.000148 = 0.999852

```{r}
misclassified_records_test <- rf_pred_test |>
  filter(.pred_class != digit)

misclassified_records_test
```

```{r}
plot_digit(misclassified_records_test[8,])
```
